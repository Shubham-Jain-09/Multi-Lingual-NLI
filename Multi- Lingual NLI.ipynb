{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.009926,
     "end_time": "2020-09-01T10:40:05.607940",
     "exception": false,
     "start_time": "2020-09-01T10:40:05.598014",
     "status": "completed"
    },
    "tags": []
   } 
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.00706,
     "end_time": "2020-09-01T10:40:05.622847",
     "exception": false,
     "start_time": "2020-09-01T10:40:05.615787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Packages\n",
    "Install and import all the required packages and modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-01T10:40:05.643888Z",
     "iopub.status.busy": "2020-09-01T10:40:05.643051Z",
     "iopub.status.idle": "2020-09-01T10:40:29.885820Z",
     "shell.execute_reply": "2020-09-01T10:40:29.884893Z"
    },
    "papermill": {
     "duration": 24.255796,
     "end_time": "2020-09-01T10:40:29.885989",
     "exception": false,
     "start_time": "2020-09-01T10:40:05.630193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.0.2\r\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 769 kB 397 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (3.0.10)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2.23.0)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.0.43)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (20.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (4.45.0)\r\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.1.91)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2020.4.4)\r\n",
      "Collecting tokenizers==0.8.1.rc1\r\n",
      "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 5.5 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (1.18.5)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (3.0.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2020.6.20)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (1.24.3)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (7.1.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (1.14.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (0.14.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.2) (2.4.7)\r\n",
      "\u001b[31mERROR: allennlp 1.0.0 has requirement transformers<2.12,>=2.9, but you'll have transformers 3.0.2 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: tokenizers, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.7.0\r\n",
      "    Uninstalling tokenizers-0.7.0:\r\n",
      "      Successfully uninstalled tokenizers-0.7.0\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 2.11.0\r\n",
      "    Uninstalling transformers-2.11.0:\r\n",
      "      Successfully uninstalled transformers-2.11.0\r\n",
      "Successfully installed tokenizers-0.8.1rc1 transformers-3.0.2\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "## installing the latest transformers version from pip\n",
    "!pip install transformers==3.0.2\n",
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-01T10:40:29.918943Z",
     "iopub.status.busy": "2020-09-01T10:40:29.918048Z",
     "iopub.status.idle": "2020-09-01T10:40:29.947985Z",
     "shell.execute_reply": "2020-09-01T10:40:29.947004Z"
    },
    "papermill": {
     "duration": 0.050085,
     "end_time": "2020-09-01T10:40:29.948189",
     "exception": false,
     "start_time": "2020-09-01T10:40:29.898104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0\n",
      "Transformers version: 3.0.2\n"
     ]
    }
   ],
   "source": [
    "## importing packages\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import transformers\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010585,
     "end_time": "2020-09-01T10:40:29.970191",
     "exception": false,
     "start_time": "2020-09-01T10:40:29.959606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration\n",
    "This is the most important section of the notebook. The configuration class is setup to define as many levers required for experiments as possible. It is meant to experiment on the following:\n",
    "\n",
    "* Different Huggingface models with Tensorflow\n",
    "* Different hyper-parameter spaces for models\n",
    "* Different seeds, splits, accelerators\n",
    "* Different learning rates (WIP)\n",
    "* Different augmentations (WIP)\n",
    "\n",
    "And all of this is possible just by changing one line of code!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:40:30.002205Z",
     "iopub.status.busy": "2020-09-01T10:40:29.996465Z",
     "iopub.status.idle": "2020-09-01T10:40:30.024906Z",
     "shell.execute_reply": "2020-09-01T10:40:30.025632Z"
    },
    "papermill": {
     "duration": 0.044728,
     "end_time": "2020-09-01T10:40:30.025803",
     "exception": false,
     "start_time": "2020-09-01T10:40:29.981075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## defining configuration\n",
    "class Configuration():\n",
    "    \"\"\"\n",
    "    All configuration for running an experiment\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        max_length = 64,\n",
    "        padding = True,\n",
    "        batch_size = 128,\n",
    "        epochs = 5,\n",
    "        metrics = [\"sparse_categorical_accuracy\"],\n",
    "        verbose = 1,\n",
    "        train_splits = 5,\n",
    "        accelerator = \"TPU\",\n",
    "        myluckynumber = 13\n",
    "    ):\n",
    "        # seed and accelerator\n",
    "        self.SEED = myluckynumber\n",
    "        self.ACCELERATOR = accelerator\n",
    "\n",
    "        # paths\n",
    "        self.PATH_TRAIN = Path(\"/kaggle/input/contradictory-my-dear-watson/train.csv\")\n",
    "        self.PATH_TEST  = Path(\"/kaggle/input/contradictory-my-dear-watson/test.csv\")\n",
    "\n",
    "        # splits\n",
    "        self.TRAIN_SPLITS = train_splits\n",
    "\n",
    "        # mapping of language\n",
    "        self.LANGUAGE_MAP = {\n",
    "            \"English\"   : 0,\n",
    "            \"Chinese\"   : 1,\n",
    "            \"Arabic\"    : 2,\n",
    "            \"French\"    : 3,\n",
    "            \"Swahili\"   : 4,\n",
    "            \"Urdu\"      : 5,\n",
    "            \"Vietnamese\": 6,\n",
    "            \"Russian\"   : 7,\n",
    "            \"Hindi\"     : 8,\n",
    "            \"Greek\"     : 9,\n",
    "            \"Thai\"      : 10,\n",
    "            \"Spanish\"   : 11,\n",
    "            \"German\"    : 12,\n",
    "            \"Turkish\"   : 13,\n",
    "            \"Bulgarian\" : 14\n",
    "        }\n",
    "\n",
    "        self.INVERSE_LANGUAGE_MAP = {v: k for k, v in self.LANGUAGE_MAP.items()}\n",
    "\n",
    "        # model configuration\n",
    "        self.MODEL_NAME = model_name\n",
    "        self.TOKENIZER = AutoTokenizer.from_pretrained(self.MODEL_NAME)\n",
    "\n",
    "        # model hyperparameters\n",
    "        self.MAX_LENGTH = max_length\n",
    "        self.PAD_TO_MAX_LENGTH = padding\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.EPOCHS = epochs\n",
    "        self.METRICS = metrics\n",
    "        self.VERBOSE = verbose\n",
    "        \n",
    "        # initializing accelerator\n",
    "        self.initialize_accelerator()\n",
    "        \n",
    "    def initialize_accelerator(self):\n",
    "        \"\"\"\n",
    "        Initializing accelerator\n",
    "        \"\"\"\n",
    "        # checking TPU first\n",
    "        if self.ACCELERATOR == \"TPU\":\n",
    "            print(\"Connecting to TPU\")\n",
    "            try:\n",
    "                tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "                print(f\"Running on TPU {tpu.master()}\")\n",
    "            except ValueError:\n",
    "                print(\"Could not connect to TPU\")\n",
    "                tpu = None\n",
    "\n",
    "            if tpu:\n",
    "                try:\n",
    "                    print(\"Initializing TPU\")\n",
    "                    tf.config.experimental_connect_to_cluster(tpu)\n",
    "                    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "                    self.strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "                    self.tpu = tpu\n",
    "                    print(\"TPU initialized\")\n",
    "                except None:\n",
    "                    print(\"Failed to initialize TPU\")\n",
    "            else:\n",
    "                print(\"Unable to initialize TPU\")\n",
    "                self.ACCELERATOR = \"GPU\"\n",
    "\n",
    "        # default for CPU and GPU\n",
    "        if self.ACCELERATOR != \"TPU\":\n",
    "            print(\"Using default strategy for CPU and single GPU\")\n",
    "            self.strategy = tf.distribute.get_strategy()\n",
    "\n",
    "        # checking GPUs\n",
    "        if self.ACCELERATOR == \"GPU\":\n",
    "            print(f\"GPUs Available: {len(tf.config.experimental.list_physical_devices('GPU'))}\")\n",
    "\n",
    "        # defining replicas\n",
    "        self.AUTO = tf.data.experimental.AUTOTUNE\n",
    "        self.REPLICAS = self.strategy.num_replicas_in_sync\n",
    "        print(f\"REPLICAS: {self.REPLICAS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010899,
     "end_time": "2020-09-01T10:40:30.048177",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.037278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation\n",
    "Preprocessing the textual data as well as tokenizing it into the encoding format for the model.   \n",
    "Finally the data is converted into a tf.data.Dataset so that it works seamlessly across accelerators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:40:30.084170Z",
     "iopub.status.busy": "2020-09-01T10:40:30.083185Z",
     "iopub.status.idle": "2020-09-01T10:40:30.087114Z",
     "shell.execute_reply": "2020-09-01T10:40:30.086369Z"
    },
    "papermill": {
     "duration": 0.027985,
     "end_time": "2020-09-01T10:40:30.087239",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.059254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## data preparation functions\n",
    "def encode_text(df, tokenizer, max_len, padding):\n",
    "    \"\"\"\n",
    "    Preprocessing textual data into encoded tokens\n",
    "    \"\"\"\n",
    "    text = df[[\"premise\", \"hypothesis\"]].values.tolist()\n",
    "\n",
    "    # encoding text using tokenizer of the model\n",
    "    text_encoded = tokenizer.batch_encode_plus(\n",
    "        text,\n",
    "        pad_to_max_length = padding,\n",
    "        max_length = max_len\n",
    "    )\n",
    "\n",
    "    return text_encoded\n",
    "\n",
    "\n",
    "def get_tf_dataset(X, y, auto, labelled = True, repeat = False, shuffle = False, batch_size = 128):\n",
    "    \"\"\"\n",
    "    Creating tf.data.Dataset for TPU\n",
    "    \"\"\"\n",
    "    if labelled:\n",
    "        ds = (tf.data.Dataset.from_tensor_slices((X[\"input_ids\"], y)))\n",
    "    else:\n",
    "        ds = (tf.data.Dataset.from_tensor_slices(X[\"input_ids\"]))\n",
    "\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(2048)\n",
    "\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(auto)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010961,
     "end_time": "2020-09-01T10:40:30.109257",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.098296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Deep Learning model architecture\n",
    "Defining the deep learning network architecture along with the model configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:40:30.143829Z",
     "iopub.status.busy": "2020-09-01T10:40:30.142811Z",
     "iopub.status.idle": "2020-09-01T10:40:30.147158Z",
     "shell.execute_reply": "2020-09-01T10:40:30.146372Z"
    },
    "papermill": {
     "duration": 0.026825,
     "end_time": "2020-09-01T10:40:30.147291",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.120466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## building model\n",
    "def build_model(model_name, max_len, metrics):\n",
    "    \"\"\"\n",
    "    Building the Deep Learning architecture\n",
    "    \"\"\"\n",
    "    # defining encoded inputs\n",
    "    input_ids = Input(shape = (max_len,), dtype = tf.int32, name = \"input_ids\")\n",
    "    \n",
    "    # defining transformer model embeddings\n",
    "    transformer_model = TFAutoModel.from_pretrained(model_name)\n",
    "    transformer_embeddings = transformer_model(input_ids)[0]\n",
    "    \n",
    "    # defining output layer\n",
    "    output_values = Dense(3, activation = \"softmax\")(transformer_embeddings[:, 0, :])\n",
    "\n",
    "    # defining model\n",
    "    model = Model(inputs = input_ids, outputs = output_values)\n",
    "    opt = Adam(learning_rate = 1e-5)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "    metrics = metrics\n",
    "\n",
    "    model.compile(optimizer = opt, loss = loss, metrics = metrics)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010778,
     "end_time": "2020-09-01T10:40:30.169331",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.158553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Stratified K-Fold Modelling\n",
    "The model is run by splitting the training data into k-fold stratified on language and label. The function returns the out-of-fold train data predictions as well as the fold-averaged test predictions which can further conveniently be used for blending and stacking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:40:30.203807Z",
     "iopub.status.busy": "2020-09-01T10:40:30.202943Z",
     "iopub.status.idle": "2020-09-01T10:40:30.232430Z",
     "shell.execute_reply": "2020-09-01T10:40:30.231487Z"
    },
    "papermill": {
     "duration": 0.051184,
     "end_time": "2020-09-01T10:40:30.232572",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.181388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## stratified k-fold over language and label\n",
    "def run_model(config):\n",
    "    \"\"\"\n",
    "    Running the model\n",
    "    \"\"\"\n",
    "    ## reading data\n",
    "    df_train = pd.read_csv(config.PATH_TRAIN)\n",
    "    df_test = pd.read_csv(config.PATH_TEST)\n",
    "\n",
    "    # adding column for stratified splitting\n",
    "    df_train[\"language_label\"] = df_train.language.astype(str) + \"_\" + df_train.label.astype(str)\n",
    "\n",
    "    # stratified K-fold on language and label\n",
    "    skf = StratifiedKFold(n_splits = config.TRAIN_SPLITS, shuffle = True, random_state = config.SEED)\n",
    "\n",
    "    # initializing predictions\n",
    "    preds_oof = np.zeros((df_train.shape[0], 3))\n",
    "    preds_test = np.zeros((df_test.shape[0], 3))\n",
    "    acc_oof = []\n",
    "\n",
    "    # iterating over folds\n",
    "    for (fold, (train_index, valid_index)) in enumerate(skf.split(df_train, df_train.language_label)):\n",
    "        # initializing TPU\n",
    "        if config.ACCELERATOR == \"TPU\":\n",
    "            if config.tpu:\n",
    "                config.initialize_accelerator()\n",
    "\n",
    "        # building model\n",
    "        K.clear_session()\n",
    "        with config.strategy.scope():\n",
    "            model = build_model(config.MODEL_NAME, config.MAX_LENGTH, config.METRICS)\n",
    "            if fold == 0:\n",
    "                print(model.summary())\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(\"#\" * 19)\n",
    "        print(f\"##### Fold: {fold + 1} #####\")\n",
    "        print(\"#\" * 19)\n",
    "\n",
    "        # splitting data into training and validation\n",
    "        X_train = df_train.iloc[train_index]\n",
    "        X_valid = df_train.iloc[valid_index]\n",
    "\n",
    "        y_train = X_train.label.values\n",
    "        y_valid = X_valid.label.values\n",
    "\n",
    "        print(\"\\nTokenizing\")\n",
    "\n",
    "        # encoding text data using tokenizer\n",
    "        X_train_encoded = encode_text(df = X_train, tokenizer = config.TOKENIZER, max_len = config.MAX_LENGTH, padding = config.PAD_TO_MAX_LENGTH)\n",
    "        X_valid_encoded = encode_text(df = X_valid, tokenizer = config.TOKENIZER, max_len = config.MAX_LENGTH, padding = config.PAD_TO_MAX_LENGTH)\n",
    "\n",
    "        # creating TF Dataset\n",
    "        ds_train = get_tf_dataset(X_train_encoded, y_train, config.AUTO, repeat = True, shuffle = True, batch_size = config.BATCH_SIZE * config.REPLICAS)\n",
    "        ds_valid = get_tf_dataset(X_valid_encoded, y_valid, config.AUTO, batch_size = config.BATCH_SIZE * config.REPLICAS * 4)\n",
    "\n",
    "        n_train = X_train.shape[0]\n",
    "\n",
    "        if fold == 0:\n",
    "            X_test_encoded = encode_text(df = df_test, tokenizer = config.TOKENIZER, max_len = config.MAX_LENGTH, padding = config.PAD_TO_MAX_LENGTH)\n",
    "\n",
    "        # saving model at best accuracy epoch\n",
    "        sv = tf.keras.callbacks.ModelCheckpoint(\n",
    "            \"model.h5\",\n",
    "            monitor = \"val_sparse_categorical_accuracy\",\n",
    "            verbose = 0,\n",
    "            save_best_only = True,\n",
    "            save_weights_only = True,\n",
    "            mode = \"max\",\n",
    "            save_freq = \"epoch\"\n",
    "        )\n",
    "\n",
    "        print(\"\\nTraining\")\n",
    "\n",
    "        # training model\n",
    "        model_history = model.fit(\n",
    "            ds_train,\n",
    "            epochs = config.EPOCHS,\n",
    "            callbacks = [sv],\n",
    "            steps_per_epoch = n_train / config.BATCH_SIZE // config.REPLICAS,\n",
    "            validation_data = ds_valid,\n",
    "            verbose = config.VERBOSE\n",
    "        )\n",
    "\n",
    "        print(\"\\nValidating\")\n",
    "\n",
    "        # scoring validation data\n",
    "        model.load_weights(\"model.h5\")\n",
    "        ds_valid = get_tf_dataset(X_valid_encoded, -1, config.AUTO, labelled = False, batch_size = config.BATCH_SIZE * config.REPLICAS * 4)\n",
    "\n",
    "        preds_valid = model.predict(ds_valid, verbose = config.VERBOSE)\n",
    "        acc = accuracy_score(y_valid, np.argmax(preds_valid, axis = 1))\n",
    "\n",
    "        preds_oof[valid_index] = preds_valid\n",
    "        acc_oof.append(acc)\n",
    "\n",
    "        print(\"\\nInferencing\")\n",
    "\n",
    "        # scoring test data\n",
    "        ds_test = get_tf_dataset(X_test_encoded, -1, config.AUTO, labelled = False, batch_size = config.BATCH_SIZE * config.REPLICAS * 4)\n",
    "        preds_test += model.predict(ds_test, verbose = config.VERBOSE) / config.TRAIN_SPLITS\n",
    "\n",
    "        print(f\"\\nFold {fold + 1} Accuracy: {round(acc, 4)}\\n\")\n",
    "\n",
    "        g = gc.collect()\n",
    "\n",
    "    # overall CV score and standard deviation\n",
    "    print(f\"\\nCV Mean Accuracy: {round(np.mean(acc_oof), 4)}\")\n",
    "    print(f\"CV StdDev Accuracy: {round(np.std(acc_oof), 4)}\\n\")\n",
    "\n",
    "    return preds_oof, preds_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.011333,
     "end_time": "2020-09-01T10:40:30.255230",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.243897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Experimenting with different models\n",
    "The list of HuggingFace models with Tensorflow can be viewed here: https://huggingface.co/models?filter=tf   \n",
    "Trying out different models is as easy as a one-line change while creating the configuration. You can uncomment the different model codes and run the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-09-01T10:40:30.284696Z",
     "iopub.status.busy": "2020-09-01T10:40:30.283653Z",
     "iopub.status.idle": "2020-09-01T10:40:30.287066Z",
     "shell.execute_reply": "2020-09-01T10:40:30.286298Z"
    },
    "papermill": {
     "duration": 0.02003,
     "end_time": "2020-09-01T10:40:30.287193",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.267163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model 1: Multilingual Bert Base Cased\n",
    "#config_1 = Configuration(\"bert-base-multilingual-cased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2)\n",
    "#preds_train_1, preds_test_1 = run_model(config_1)\n",
    "\n",
    "# Model 2: Distilbert Base Uncased\n",
    "#config_2 = Configuration(\"distilbert-base-uncased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2)\n",
    "#preds_train_2, preds_test_2 = run_model(config_2)\n",
    "\n",
    "# Model 3: XLM Roberta Base\n",
    "#config_3 = Configuration(\"jplu/tf-xlm-roberta-base\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2)\n",
    "#preds_train_3, preds_test_3 = run_model(config_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010851,
     "end_time": "2020-09-01T10:40:30.310733",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.299882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tuning hyperparameters\n",
    "Experimenting with different hyperparameters only requires a one-line change while creating the configuration. You can uncomment the different hyperparameter spaces code and run the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-09-01T10:40:30.339170Z",
     "iopub.status.busy": "2020-09-01T10:40:30.338258Z",
     "iopub.status.idle": "2020-09-01T10:40:30.342476Z",
     "shell.execute_reply": "2020-09-01T10:40:30.341639Z"
    },
    "papermill": {
     "duration": 0.020718,
     "end_time": "2020-09-01T10:40:30.342627",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.321909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Space 1\n",
    "#config_1 = Configuration(\"bert-base-multilingual-cased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2)\n",
    "#preds_train_1, preds_test_1 = run_model(config_1)\n",
    "\n",
    "# Hyperparameter Space 2\n",
    "#config_2 = Configuration(\"bert-base-multilingual-cased\", max_length = 64, batch_size = 32, epochs = 3, train_splits = 2)\n",
    "#preds_train_2, preds_test_2 = run_model(config_2)\n",
    "\n",
    "#Hyperparameter Space 3\n",
    "# config_3 = Configuration(\"xlnet-large-cased\", max_length = 84, batch_size = 16, epochs = 4, train_splits = 2)\n",
    "# preds_train_3, preds_test_3 = run_model(config_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.011002,
     "end_time": "2020-09-01T10:40:30.365052",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.354050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transitioning across accelerators\n",
    "Running the models on TPU, GPU or CPU can be configured without changing any code.  \n",
    "Note that for running on TPU (or GPU), the corresponding Accelerator must be chosen in the Kaggle Notebook settings. You can uncomment the different accelerator codes and run the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T10:40:30.395068Z",
     "iopub.status.busy": "2020-09-01T10:40:30.393752Z",
     "iopub.status.idle": "2020-09-01T10:40:30.397708Z",
     "shell.execute_reply": "2020-09-01T10:40:30.396847Z"
    },
    "papermill": {
     "duration": 0.021455,
     "end_time": "2020-09-01T10:40:30.397837",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.376382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TPU\n",
    "#config_1 = Configuration(\"bert-base-multilingual-cased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2, accelerator = \"TPU\")\n",
    "#preds_train_1, preds_test_1 = run_model(config_1)\n",
    "\n",
    "# GPU\n",
    "#config_2 = Configuration(\"bert-base-multilingual-cased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2, accelerator = \"GPU\")\n",
    "#preds_train_2, preds_test_2 = run_model(config_2)\n",
    "\n",
    "# CPU\n",
    "#config_3 = Configuration(\"bert-base-multilingual-cased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2, accelerator = \"CPU\")\n",
    "#preds_train_3, preds_test_3 = run_model(config_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010922,
     "end_time": "2020-09-01T10:40:30.420601",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.409679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final model\n",
    "Building final model after tuning hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-09-01T10:40:30.449756Z",
     "iopub.status.busy": "2020-09-01T10:40:30.448961Z",
     "iopub.status.idle": "2020-09-01T11:35:24.963832Z",
     "shell.execute_reply": "2020-09-01T11:35:24.962807Z"
    },
    "papermill": {
     "duration": 3294.532172,
     "end_time": "2020-09-01T11:35:24.963983",
     "exception": false,
     "start_time": "2020-09-01T10:40:30.431811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42a6a68684c4773967d91b8fa8e99da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=513.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508c2db5d3ab48a28f9a85c958cdbb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connecting to TPU\n",
      "Running on TPU grpc://10.0.0.2:8470\n",
      "Initializing TPU\n",
      "TPU initialized\n",
      "REPLICAS: 8\n",
      "Connecting to TPU\n",
      "Running on TPU grpc://10.0.0.2:8470\n",
      "Initializing TPU\n",
      "TPU initialized\n",
      "REPLICAS: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b58dd6a4f68401592e537aa33d3a7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=3271420488.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_ids (InputLayer)       [(None, 84)]              0         \n",
      "_________________________________________________________________\n",
      "tf_roberta_model (TFRobertaM ((None, 84, 1024), (None, 559890432 \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 1024)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 559,893,507\n",
      "Trainable params: 559,893,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "###################\n",
      "##### Fold: 1 #####\n",
      "###################\n",
      "\n",
      "Tokenizing\n",
      "\n",
      "Training\n",
      "Epoch 1/16\n",
      "35/35 [==============================] - 59s 2s/step - sparse_categorical_accuracy: 0.3415 - loss: 1.1009 - val_sparse_categorical_accuracy: 0.3455 - val_loss: 1.1008\n",
      "Epoch 2/16\n",
      "35/35 [==============================] - 15s 434ms/step - sparse_categorical_accuracy: 0.3471 - loss: 1.0997 - val_sparse_categorical_accuracy: 0.3455 - val_loss: 1.0974\n",
      "Epoch 3/16\n",
      "35/35 [==============================] - 24s 683ms/step - sparse_categorical_accuracy: 0.4593 - loss: 1.0376 - val_sparse_categorical_accuracy: 0.4944 - val_loss: 1.0116\n",
      "Epoch 4/16\n",
      "35/35 [==============================] - 24s 674ms/step - sparse_categorical_accuracy: 0.6490 - loss: 0.8875 - val_sparse_categorical_accuracy: 0.7294 - val_loss: 0.8133\n",
      "Epoch 5/16\n",
      "35/35 [==============================] - 40s 1s/step - sparse_categorical_accuracy: 0.7256 - loss: 0.8213 - val_sparse_categorical_accuracy: 0.7376 - val_loss: 0.8082\n",
      "Epoch 6/16\n",
      "35/35 [==============================] - 23s 662ms/step - sparse_categorical_accuracy: 0.7677 - loss: 0.7791 - val_sparse_categorical_accuracy: 0.7653 - val_loss: 0.7772\n",
      "Epoch 7/16\n",
      "35/35 [==============================] - 45s 1s/step - sparse_categorical_accuracy: 0.8007 - loss: 0.7463 - val_sparse_categorical_accuracy: 0.7845 - val_loss: 0.7607\n",
      "Epoch 8/16\n",
      "35/35 [==============================] - 33s 948ms/step - sparse_categorical_accuracy: 0.8254 - loss: 0.7221 - val_sparse_categorical_accuracy: 0.7970 - val_loss: 0.7490\n",
      "Epoch 9/16\n",
      "35/35 [==============================] - 15s 438ms/step - sparse_categorical_accuracy: 0.8387 - loss: 0.7106 - val_sparse_categorical_accuracy: 0.7832 - val_loss: 0.7634\n",
      "Epoch 10/16\n",
      "35/35 [==============================] - 15s 436ms/step - sparse_categorical_accuracy: 0.8354 - loss: 0.7128 - val_sparse_categorical_accuracy: 0.7898 - val_loss: 0.7586\n",
      "Epoch 11/16\n",
      "35/35 [==============================] - 23s 671ms/step - sparse_categorical_accuracy: 0.8377 - loss: 0.7090 - val_sparse_categorical_accuracy: 0.8050 - val_loss: 0.7443\n",
      "Epoch 12/16\n",
      "35/35 [==============================] - 15s 437ms/step - sparse_categorical_accuracy: 0.8672 - loss: 0.6818 - val_sparse_categorical_accuracy: 0.7983 - val_loss: 0.7467\n",
      "Epoch 13/16\n",
      "35/35 [==============================] - 23s 655ms/step - sparse_categorical_accuracy: 0.8757 - loss: 0.6740 - val_sparse_categorical_accuracy: 0.8073 - val_loss: 0.7383\n",
      "Epoch 14/16\n",
      "35/35 [==============================] - 15s 435ms/step - sparse_categorical_accuracy: 0.8779 - loss: 0.6712 - val_sparse_categorical_accuracy: 0.7944 - val_loss: 0.7519\n",
      "Epoch 15/16\n",
      "35/35 [==============================] - 15s 435ms/step - sparse_categorical_accuracy: 0.8743 - loss: 0.6742 - val_sparse_categorical_accuracy: 0.7947 - val_loss: 0.7516\n",
      "Epoch 16/16\n",
      "35/35 [==============================] - 15s 433ms/step - sparse_categorical_accuracy: 0.8916 - loss: 0.6579 - val_sparse_categorical_accuracy: 0.8046 - val_loss: 0.7441\n",
      "\n",
      "Validating\n",
      "3/3 [==============================] - 12s 4s/step\n",
      "\n",
      "Inferencing\n",
      "6/6 [==============================] - 11s 2s/step\n",
      "\n",
      "Fold 1 Accuracy: 0.8073\n",
      "\n",
      "Connecting to TPU\n",
      "Running on TPU grpc://10.0.0.2:8470\n",
      "Initializing TPU\n",
      "TPU initialized\n",
      "REPLICAS: 8\n",
      "\n",
      "\n",
      "###################\n",
      "##### Fold: 2 #####\n",
      "###################\n",
      "\n",
      "Tokenizing\n",
      "\n",
      "Training\n",
      "Epoch 1/16\n",
      "35/35 [==============================] - 58s 2s/step - sparse_categorical_accuracy: 0.3462 - loss: 1.1023 - val_sparse_categorical_accuracy: 0.3455 - val_loss: 1.1009\n",
      "Epoch 2/16\n",
      "35/35 [==============================] - 23s 671ms/step - sparse_categorical_accuracy: 0.4198 - loss: 1.0710 - val_sparse_categorical_accuracy: 0.5558 - val_loss: 0.9675\n",
      "Epoch 3/16\n",
      "35/35 [==============================] - 39s 1s/step - sparse_categorical_accuracy: 0.6519 - loss: 0.8869 - val_sparse_categorical_accuracy: 0.7066 - val_loss: 0.8353\n",
      "Epoch 4/16\n",
      "35/35 [==============================] - 36s 1s/step - sparse_categorical_accuracy: 0.7446 - loss: 0.8001 - val_sparse_categorical_accuracy: 0.7459 - val_loss: 0.7992\n",
      "Epoch 5/16\n",
      "35/35 [==============================] - 24s 676ms/step - sparse_categorical_accuracy: 0.7866 - loss: 0.7590 - val_sparse_categorical_accuracy: 0.7558 - val_loss: 0.7899\n",
      "Epoch 6/16\n",
      "35/35 [==============================] - 44s 1s/step - sparse_categorical_accuracy: 0.7962 - loss: 0.7512 - val_sparse_categorical_accuracy: 0.7766 - val_loss: 0.7705\n",
      "Epoch 7/16\n",
      "35/35 [==============================] - 33s 946ms/step - sparse_categorical_accuracy: 0.8285 - loss: 0.7223 - val_sparse_categorical_accuracy: 0.7845 - val_loss: 0.7640\n",
      "Epoch 8/16\n",
      "35/35 [==============================] - 34s 980ms/step - sparse_categorical_accuracy: 0.8450 - loss: 0.7045 - val_sparse_categorical_accuracy: 0.7924 - val_loss: 0.7562\n",
      "Epoch 9/16\n",
      "35/35 [==============================] - 15s 435ms/step - sparse_categorical_accuracy: 0.8566 - loss: 0.6928 - val_sparse_categorical_accuracy: 0.7835 - val_loss: 0.7623\n",
      "Epoch 10/16\n",
      "35/35 [==============================] - 15s 436ms/step - sparse_categorical_accuracy: 0.8647 - loss: 0.6851 - val_sparse_categorical_accuracy: 0.7881 - val_loss: 0.7590\n",
      "Epoch 11/16\n",
      "35/35 [==============================] - 15s 435ms/step - sparse_categorical_accuracy: 0.8795 - loss: 0.6706 - val_sparse_categorical_accuracy: 0.7901 - val_loss: 0.7589\n",
      "Epoch 12/16\n",
      "35/35 [==============================] - 15s 436ms/step - sparse_categorical_accuracy: 0.8874 - loss: 0.6626 - val_sparse_categorical_accuracy: 0.7805 - val_loss: 0.7675\n",
      "Epoch 13/16\n",
      "35/35 [==============================] - 23s 661ms/step - sparse_categorical_accuracy: 0.8884 - loss: 0.6621 - val_sparse_categorical_accuracy: 0.7957 - val_loss: 0.7514\n",
      "Epoch 14/16\n",
      "35/35 [==============================] - 23s 656ms/step - sparse_categorical_accuracy: 0.8895 - loss: 0.6603 - val_sparse_categorical_accuracy: 0.7970 - val_loss: 0.7514\n",
      "Epoch 15/16\n",
      "35/35 [==============================] - 40s 1s/step - sparse_categorical_accuracy: 0.8965 - loss: 0.6533 - val_sparse_categorical_accuracy: 0.8023 - val_loss: 0.7466\n",
      "Epoch 16/16\n",
      "35/35 [==============================] - 34s 961ms/step - sparse_categorical_accuracy: 0.8998 - loss: 0.6509 - val_sparse_categorical_accuracy: 0.8036 - val_loss: 0.7450\n",
      "\n",
      "Validating\n",
      "3/3 [==============================] - 12s 4s/step\n",
      "\n",
      "Inferencing\n",
      "6/6 [==============================] - 11s 2s/step\n",
      "\n",
      "Fold 2 Accuracy: 0.8036\n",
      "\n",
      "Connecting to TPU\n",
      "Running on TPU grpc://10.0.0.2:8470\n",
      "Initializing TPU\n",
      "TPU initialized\n",
      "REPLICAS: 8\n",
      "\n",
      "\n",
      "###################\n",
      "##### Fold: 3 #####\n",
      "###################\n",
      "\n",
      "Tokenizing\n",
      "\n",
      "Training\n",
      "Epoch 1/16\n",
      "35/35 [==============================] - 60s 2s/step - sparse_categorical_accuracy: 0.3426 - loss: 1.1073 - val_sparse_categorical_accuracy: 0.3323 - val_loss: 1.0993\n",
      "Epoch 2/16\n",
      "35/35 [==============================] - 23s 671ms/step - sparse_categorical_accuracy: 0.3339 - loss: 1.1079 - val_sparse_categorical_accuracy: 0.3442 - val_loss: 1.0974\n",
      "Epoch 3/16\n",
      "35/35 [==============================] - 39s 1s/step - sparse_categorical_accuracy: 0.3625 - loss: 1.0990 - val_sparse_categorical_accuracy: 0.4145 - val_loss: 1.0690\n",
      "Epoch 4/16\n",
      "35/35 [==============================] - 51s 1s/step - sparse_categorical_accuracy: 0.4705 - loss: 1.0402 - val_sparse_categorical_accuracy: 0.5653 - val_loss: 0.9736\n",
      "Epoch 5/16\n",
      "35/35 [==============================] - 23s 662ms/step - sparse_categorical_accuracy: 0.6350 - loss: 0.8991 - val_sparse_categorical_accuracy: 0.7132 - val_loss: 0.8313\n",
      "Epoch 6/16\n",
      "35/35 [==============================] - 23s 656ms/step - sparse_categorical_accuracy: 0.7296 - loss: 0.8150 - val_sparse_categorical_accuracy: 0.7370 - val_loss: 0.8069\n",
      "Epoch 7/16\n",
      "35/35 [==============================] - 40s 1s/step - sparse_categorical_accuracy: 0.7523 - loss: 0.7931 - val_sparse_categorical_accuracy: 0.7601 - val_loss: 0.7871\n",
      "Epoch 8/16\n",
      "35/35 [==============================] - 52s 1s/step - sparse_categorical_accuracy: 0.7923 - loss: 0.7528 - val_sparse_categorical_accuracy: 0.7769 - val_loss: 0.7702\n",
      "Epoch 9/16\n",
      "35/35 [==============================] - 15s 440ms/step - sparse_categorical_accuracy: 0.8153 - loss: 0.7319 - val_sparse_categorical_accuracy: 0.7762 - val_loss: 0.7711\n",
      "Epoch 10/16\n",
      "35/35 [==============================] - 24s 674ms/step - sparse_categorical_accuracy: 0.8355 - loss: 0.7115 - val_sparse_categorical_accuracy: 0.7914 - val_loss: 0.7580\n",
      "Epoch 11/16\n",
      "35/35 [==============================] - 23s 666ms/step - sparse_categorical_accuracy: 0.8500 - loss: 0.6985 - val_sparse_categorical_accuracy: 0.7917 - val_loss: 0.7547\n",
      "Epoch 12/16\n",
      "35/35 [==============================] - 44s 1s/step - sparse_categorical_accuracy: 0.8623 - loss: 0.6875 - val_sparse_categorical_accuracy: 0.7927 - val_loss: 0.7557\n",
      "Epoch 13/16\n",
      "35/35 [==============================] - 15s 436ms/step - sparse_categorical_accuracy: 0.8657 - loss: 0.6822 - val_sparse_categorical_accuracy: 0.7888 - val_loss: 0.7599\n",
      "Epoch 14/16\n",
      "35/35 [==============================] - 15s 434ms/step - sparse_categorical_accuracy: 0.8750 - loss: 0.6740 - val_sparse_categorical_accuracy: 0.7881 - val_loss: 0.7587\n",
      "Epoch 15/16\n",
      "35/35 [==============================] - 23s 659ms/step - sparse_categorical_accuracy: 0.8850 - loss: 0.6646 - val_sparse_categorical_accuracy: 0.8010 - val_loss: 0.7469\n",
      "Epoch 16/16\n",
      "35/35 [==============================] - 23s 655ms/step - sparse_categorical_accuracy: 0.8945 - loss: 0.6543 - val_sparse_categorical_accuracy: 0.8023 - val_loss: 0.7449\n",
      "\n",
      "Validating\n",
      "3/3 [==============================] - 13s 4s/step\n",
      "\n",
      "Inferencing\n",
      "6/6 [==============================] - 11s 2s/step\n",
      "\n",
      "Fold 3 Accuracy: 0.8023\n",
      "\n",
      "Connecting to TPU\n",
      "Running on TPU grpc://10.0.0.2:8470\n",
      "Initializing TPU\n",
      "TPU initialized\n",
      "REPLICAS: 8\n",
      "\n",
      "\n",
      "###################\n",
      "##### Fold: 4 #####\n",
      "###################\n",
      "\n",
      "Tokenizing\n",
      "\n",
      "Training\n",
      "Epoch 1/16\n",
      "35/35 [==============================] - 58s 2s/step - sparse_categorical_accuracy: 0.3254 - loss: 1.1048 - val_sparse_categorical_accuracy: 0.3442 - val_loss: 1.0988\n",
      "Epoch 2/16\n",
      "35/35 [==============================] - 15s 435ms/step - sparse_categorical_accuracy: 0.3494 - loss: 1.0977 - val_sparse_categorical_accuracy: 0.3439 - val_loss: 1.0870\n",
      "Epoch 3/16\n",
      "35/35 [==============================] - 23s 664ms/step - sparse_categorical_accuracy: 0.4475 - loss: 1.0443 - val_sparse_categorical_accuracy: 0.5746 - val_loss: 0.9619\n",
      "Epoch 4/16\n",
      "35/35 [==============================] - 23s 654ms/step - sparse_categorical_accuracy: 0.6705 - loss: 0.8708 - val_sparse_categorical_accuracy: 0.7429 - val_loss: 0.8024\n",
      "Epoch 5/16\n",
      "35/35 [==============================] - 39s 1s/step - sparse_categorical_accuracy: 0.7477 - loss: 0.7985 - val_sparse_categorical_accuracy: 0.7545 - val_loss: 0.7902\n",
      "Epoch 6/16\n",
      "35/35 [==============================] - 38s 1s/step - sparse_categorical_accuracy: 0.7766 - loss: 0.7689 - val_sparse_categorical_accuracy: 0.7729 - val_loss: 0.7732\n",
      "Epoch 7/16\n",
      "35/35 [==============================] - 25s 721ms/step - sparse_categorical_accuracy: 0.8009 - loss: 0.7458 - val_sparse_categorical_accuracy: 0.7871 - val_loss: 0.7582\n",
      "Epoch 8/16\n",
      "35/35 [==============================] - 15s 436ms/step - sparse_categorical_accuracy: 0.8350 - loss: 0.7136 - val_sparse_categorical_accuracy: 0.7842 - val_loss: 0.7628\n",
      "Epoch 9/16\n",
      "35/35 [==============================] - 15s 438ms/step - sparse_categorical_accuracy: 0.8321 - loss: 0.7152 - val_sparse_categorical_accuracy: 0.7845 - val_loss: 0.7616\n",
      "Epoch 10/16\n",
      "35/35 [==============================] - 23s 661ms/step - sparse_categorical_accuracy: 0.8492 - loss: 0.6989 - val_sparse_categorical_accuracy: 0.7904 - val_loss: 0.7546\n",
      "Epoch 11/16\n",
      "35/35 [==============================] - 23s 660ms/step - sparse_categorical_accuracy: 0.8576 - loss: 0.6903 - val_sparse_categorical_accuracy: 0.7970 - val_loss: 0.7511\n",
      "Epoch 12/16\n",
      "35/35 [==============================] - 41s 1s/step - sparse_categorical_accuracy: 0.8791 - loss: 0.6699 - val_sparse_categorical_accuracy: 0.8023 - val_loss: 0.7444\n",
      "Epoch 13/16\n",
      "35/35 [==============================] - 28s 791ms/step - sparse_categorical_accuracy: 0.8883 - loss: 0.6616 - val_sparse_categorical_accuracy: 0.8050 - val_loss: 0.7417\n",
      "Epoch 14/16\n",
      "35/35 [==============================] - 15s 437ms/step - sparse_categorical_accuracy: 0.8968 - loss: 0.6529 - val_sparse_categorical_accuracy: 0.8033 - val_loss: 0.7445\n",
      "Epoch 15/16\n",
      "35/35 [==============================] - 15s 435ms/step - sparse_categorical_accuracy: 0.9041 - loss: 0.6460 - val_sparse_categorical_accuracy: 0.8040 - val_loss: 0.7441\n",
      "Epoch 16/16\n",
      "35/35 [==============================] - 23s 664ms/step - sparse_categorical_accuracy: 0.9071 - loss: 0.6431 - val_sparse_categorical_accuracy: 0.8066 - val_loss: 0.7417\n",
      "\n",
      "Validating\n",
      "3/3 [==============================] - 12s 4s/step\n",
      "\n",
      "Inferencing\n",
      "6/6 [==============================] - 11s 2s/step\n",
      "\n",
      "Fold 4 Accuracy: 0.8066\n",
      "\n",
      "\n",
      "CV Mean Accuracy: 0.805\n",
      "CV StdDev Accuracy: 0.002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Model: XLM Roberta Large\n",
    "config_1 = Configuration(\"jplu/tf-xlm-roberta-large\", max_length = 84, batch_size = 32, epochs = 16, train_splits = 4)\n",
    "preds_train_1, preds_test_1 = run_model(config_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.175328,
     "end_time": "2020-09-01T11:35:25.314967",
     "exception": false,
     "start_time": "2020-09-01T11:35:25.139639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission\n",
    "Creating the submission file by predicting the label with highest probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-01T11:35:25.670386Z",
     "iopub.status.busy": "2020-09-01T11:35:25.669489Z",
     "iopub.status.idle": "2020-09-01T11:35:26.037102Z",
     "shell.execute_reply": "2020-09-01T11:35:26.036297Z"
    },
    "papermill": {
     "duration": 0.550316,
     "end_time": "2020-09-01T11:35:26.037232",
     "exception": false,
     "start_time": "2020-09-01T11:35:25.486916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1830\n",
       "1    1739\n",
       "2    1626\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(config_1.PATH_TEST)\n",
    "\n",
    "df_submission = pd.DataFrame({\"id\": df_test.id.values, \"prediction\": np.argmax(preds_test_1, axis = 1)})\n",
    "df_submission.to_csv(\"submission.csv\", index = False)\n",
    "\n",
    "df_submission.prediction.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.174508,
     "end_time": "2020-09-01T11:35:26.387147",
     "exception": false,
     "start_time": "2020-09-01T11:35:26.212639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Elementary, My Dear Watson\n",
    "This is a bare skeletal workflow but as any competition progresses there will be new elements that would need to be added into the workflow and this process can help in scaling and iterating over experiments meticulously.\n",
    "\n",
    "Here are some open ideas to work on:\n",
    "\n",
    "* Adding data augmentation\n",
    "* Pre-processing text data before tokenization\n",
    "* Trying other models\n",
    "* Tuning hyperparameters\n",
    "* Ensembling multiple models\n",
    "\n",
    "**Good Luck!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 3326.828084,
   "end_time": "2020-09-01T11:35:26.976952",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-01T10:40:00.148868",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "074be52693ca4c07b11b0679f8816827": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0cf69163b3fe43239c911609e9117de8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "11ae897e9cb0441b9352b5a125c56733": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "131c52131e6c4ca5ba003179fced8b73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f7cee85877742089c17156fe3ebca8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20e0f9a206e649ed97d89aea0b3ecb49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3530bdbc406e4a469ced9ff2d179df80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a55d357e3b74a12bb0034fe401ec0bd",
       "max": 5069051.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bd1d5070cc4b4193ab9a70166378b68a",
       "value": 5069051.0
      }
     },
     "3a3a9e25177f42d0b6d50c8992aa60ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4384a9ce0e4f4e4db3656305766a7455": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "4913957ce9b141e3abd5162d5eb74fdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "508c2db5d3ab48a28f9a85c958cdbb88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3530bdbc406e4a469ced9ff2d179df80",
        "IPY_MODEL_b32387064fef405ba919391ec9615bed"
       ],
       "layout": "IPY_MODEL_caf228f536b14c31903bc82cf6b8d0f5"
      }
     },
     "76a262e951df4010b59d191b709de0f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "7fddc92fd3a14dc690e1d44c7c960822": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a9842c93f2794eae937210d22ca4a779",
       "placeholder": "​",
       "style": "IPY_MODEL_11ae897e9cb0441b9352b5a125c56733",
       "value": " 3.27G/3.27G [02:36&lt;00:00, 20.8MB/s]"
      }
     },
     "8a55d357e3b74a12bb0034fe401ec0bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e9e9ecc9f8f462ebc5ee4c8ba4d9337": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_074be52693ca4c07b11b0679f8816827",
       "max": 3271420488.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4384a9ce0e4f4e4db3656305766a7455",
       "value": 3271420488.0
      }
     },
     "8fa8f4f52b2447dcb30adf04b7d22670": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a6e93eefbdbb4a97a792b98f7f8f8e67",
       "max": 513.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_76a262e951df4010b59d191b709de0f0",
       "value": 513.0
      }
     },
     "9b58dd6a4f68401592e537aa33d3a7ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8e9e9ecc9f8f462ebc5ee4c8ba4d9337",
        "IPY_MODEL_7fddc92fd3a14dc690e1d44c7c960822"
       ],
       "layout": "IPY_MODEL_131c52131e6c4ca5ba003179fced8b73"
      }
     },
     "a6e93eefbdbb4a97a792b98f7f8f8e67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9842c93f2794eae937210d22ca4a779": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b32387064fef405ba919391ec9615bed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1f7cee85877742089c17156fe3ebca8d",
       "placeholder": "​",
       "style": "IPY_MODEL_3a3a9e25177f42d0b6d50c8992aa60ed",
       "value": " 5.07M/5.07M [00:03&lt;00:00, 1.35MB/s]"
      }
     },
     "bd1d5070cc4b4193ab9a70166378b68a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "caf228f536b14c31903bc82cf6b8d0f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e42a6a68684c4773967d91b8fa8e99da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8fa8f4f52b2447dcb30adf04b7d22670",
        "IPY_MODEL_fbca867de5af4345958fe2c30ab44c0e"
       ],
       "layout": "IPY_MODEL_20e0f9a206e649ed97d89aea0b3ecb49"
      }
     },
     "fbca867de5af4345958fe2c30ab44c0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0cf69163b3fe43239c911609e9117de8",
       "placeholder": "​",
       "style": "IPY_MODEL_4913957ce9b141e3abd5162d5eb74fdd",
       "value": " 513/513 [00:00&lt;00:00, 13.4kB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
